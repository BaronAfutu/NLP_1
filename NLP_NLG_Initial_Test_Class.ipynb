{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP NLG Initial Test Class.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GML - NLP\n",
        "## NLG"
      ],
      "metadata": {
        "id": "A0aYgdXNV1lG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np "
      ],
      "metadata": {
        "id": "yOyQjT3LWkMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "data = \"In the town of Athy one Lanigan\\nBattered away til he hadnt a pound.\\nHis father died and made him a man again\\nLeft him a farm and ten acres of ground.\"\n",
        "# split the paragraphs (or block) of text into lines (sentences)\n",
        "corpus = data.lower().split('\\n')\n",
        "\n",
        "corpus\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJRJxH2JWoq3",
        "outputId": "ced645b0-7a34-46f3-f072-629f70a5f286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in the town of athy one lanigan',\n",
              " 'battered away til he hadnt a pound.',\n",
              " 'his father died and made him a man again',\n",
              " 'left him a farm and ten acres of ground.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each line in the corpus, we want to generate training data in the form a stream; one word at a time.\n",
        "Help the model learn which word possibly could appear after a given word or set of words.\n",
        "\n",
        "Eg. Given the token sequence\n",
        ">[5, 6, 7, 2, 8, 9, 10]\n",
        "\n",
        "The resulting training data becomes\n",
        ">[5,6]\\\n",
        "[5,6,7]\\\n",
        "[5, 6, 7, 2]\\\n",
        "[5, 6, 7, 2, 8]\\\n",
        "[5, 6, 7, 2, 8, 9]\\\n",
        "[5, 6, 7, 2, 8, 9, 10]\n",
        "\n",
        "The first (n-1) tokens are used as input, then the nth token as output to train the system.\n",
        "\n",
        "The tells the system, if the input was \"in\"(5), the next word (output) is \"the\"(6). And if the input was \"in the\" the next word is \"town\". This goes on till the whole sentence is learned"
      ],
      "metadata": {
        "id": "U65J6f7Yw_1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tokenizer\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "lfKgBG9HZfyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputSequences = []\n",
        "\n",
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0] \n",
        "  # text_to_sentences accepts a list of sentence(s) \n",
        "  # and returns a list of sequence lists\n",
        "  for i in range(1,len(token_list)):\n",
        "    nGramSequences = token_list[:i+1]\n",
        "    inputSequences.append(nGramSequences)\n",
        "\n",
        "inputSequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S49YyFBlYjfc",
        "outputId": "c1fec70a-f219-4a84-ee03-388c5ba8bc12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 6],\n",
              " [5, 6, 7],\n",
              " [5, 6, 7, 2],\n",
              " [5, 6, 7, 2, 8],\n",
              " [5, 6, 7, 2, 8, 9],\n",
              " [5, 6, 7, 2, 8, 9, 10],\n",
              " [11, 12],\n",
              " [11, 12, 13],\n",
              " [11, 12, 13, 14],\n",
              " [11, 12, 13, 14, 15],\n",
              " [11, 12, 13, 14, 15, 1],\n",
              " [11, 12, 13, 14, 15, 1, 16],\n",
              " [17, 18],\n",
              " [17, 18, 19],\n",
              " [17, 18, 19, 3],\n",
              " [17, 18, 19, 3, 20],\n",
              " [17, 18, 19, 3, 20, 4],\n",
              " [17, 18, 19, 3, 20, 4, 1],\n",
              " [17, 18, 19, 3, 20, 4, 1, 21],\n",
              " [17, 18, 19, 3, 20, 4, 1, 21, 22],\n",
              " [23, 4],\n",
              " [23, 4, 1],\n",
              " [23, 4, 1, 24],\n",
              " [23, 4, 1, 24, 3],\n",
              " [23, 4, 1, 24, 3, 25],\n",
              " [23, 4, 1, 24, 3, 25, 26],\n",
              " [23, 4, 1, 24, 3, 25, 26, 2],\n",
              " [23, 4, 1, 24, 3, 25, 26, 2, 27]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = max([len(x) for x in inputSequences])\n",
        "inputSequences = np.array(pad_sequences(inputSequences, maxlen=max_sequence_len, padding=\"pre\"))\n",
        "inputSequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7UKOCg5z971",
        "outputId": "08027a7d-df1e-40b3-fa0e-2e2ffdfa7e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  5,  6],\n",
              "       [ 0,  0,  0,  0,  0,  0,  5,  6,  7],\n",
              "       [ 0,  0,  0,  0,  0,  5,  6,  7,  2],\n",
              "       [ 0,  0,  0,  0,  5,  6,  7,  2,  8],\n",
              "       [ 0,  0,  0,  5,  6,  7,  2,  8,  9],\n",
              "       [ 0,  0,  5,  6,  7,  2,  8,  9, 10],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 11, 12],\n",
              "       [ 0,  0,  0,  0,  0,  0, 11, 12, 13],\n",
              "       [ 0,  0,  0,  0,  0, 11, 12, 13, 14],\n",
              "       [ 0,  0,  0,  0, 11, 12, 13, 14, 15],\n",
              "       [ 0,  0,  0, 11, 12, 13, 14, 15,  1],\n",
              "       [ 0,  0, 11, 12, 13, 14, 15,  1, 16],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 17, 18],\n",
              "       [ 0,  0,  0,  0,  0,  0, 17, 18, 19],\n",
              "       [ 0,  0,  0,  0,  0, 17, 18, 19,  3],\n",
              "       [ 0,  0,  0,  0, 17, 18, 19,  3, 20],\n",
              "       [ 0,  0,  0, 17, 18, 19,  3, 20,  4],\n",
              "       [ 0,  0, 17, 18, 19,  3, 20,  4,  1],\n",
              "       [ 0, 17, 18, 19,  3, 20,  4,  1, 21],\n",
              "       [17, 18, 19,  3, 20,  4,  1, 21, 22],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 23,  4],\n",
              "       [ 0,  0,  0,  0,  0,  0, 23,  4,  1],\n",
              "       [ 0,  0,  0,  0,  0, 23,  4,  1, 24],\n",
              "       [ 0,  0,  0,  0, 23,  4,  1, 24,  3],\n",
              "       [ 0,  0,  0, 23,  4,  1, 24,  3, 25],\n",
              "       [ 0,  0, 23,  4,  1, 24,  3, 25, 26],\n",
              "       [ 0, 23,  4,  1, 24,  3, 25, 26,  2],\n",
              "       [23,  4,  1, 24,  3, 25, 26,  2, 27]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = inputSequences[:,:-1] # all rows, all expect last column\n",
        "labels = inputSequences[:,-1]  # all rows, last column\n",
        "y = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "metadata": {
        "id": "lp7n740U6fZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sentence: \",corpus[0])\n",
        "print(\"Sequence: \",tokenizer.texts_to_sequences([corpus[0]]))\n",
        "print(\"X: \",x[0])\n",
        "print(\"Label: \",labels[0])\n",
        "print(\"Y: \",y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOJDRcFA8meL",
        "outputId": "a3096c38-3e1a-4237-cb84-f1b6954cff54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  in the town of athy one lanigan\n",
            "Sequence:  [[5, 6, 7, 2, 8, 9, 10]]\n",
            "X:  [0 0 0 0 0 0 0 5]\n",
            "Label:  6\n",
            "Y:  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "history = model.fit(x, y, epochs=15, verbose=1)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-gL0-pz_OLY",
        "outputId": "b9d1032d-00bc-4984-b2f8-a6b5603f173a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step - loss: 3.3349 - accuracy: 0.0357\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2298 - accuracy: 0.1071\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0190 - accuracy: 0.1071\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.2406 - accuracy: 0.1071\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.6180 - accuracy: 0.2857\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.4564 - accuracy: 0.5000\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2489 - accuracy: 0.3214\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.9277 - accuracy: 0.2857\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5950 - accuracy: 0.5000\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.2640 - accuracy: 0.6429\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.0581 - accuracy: 0.7143\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.8605 - accuracy: 0.7143\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6647 - accuracy: 0.8929\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4978 - accuracy: 0.8929\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3870 - accuracy: 0.8929\n",
            "<keras.engine.sequential.Sequential object at 0x7fd89964cd50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"a farm he had\"\n",
        "next_words = 10\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4aIwv0PBLE-",
        "outputId": "00f7a905-f71d-4e6f-bf9e-91ef36cf4a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a farm he had a farm and ten acres ground ground ground ground ground\n"
          ]
        }
      ]
    }
  ]
}